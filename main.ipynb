{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep569/bengali_question_answering_model-and-tokenizer_training/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e1WesaQs3E_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "oJ30pbgHYe-p",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ok\n"
      ],
      "metadata": {
        "id": "D6uJknKR2Bvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "PCs7rNylLjmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U PyPDF2\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "l9PhAQicEyQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "dWyzGAHTw2y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir my"
      ],
      "metadata": {
        "id": "wUAS19ny89Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItYpaZD9EH7J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "import docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"csebuetnlp/BanglaNMT\")"
      ],
      "metadata": {
        "id": "sf0m0jHUYeru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "N5kbpvaJYe0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Replace 'dataset_name' with the name of your dataset\n",
        "dataset_name = \"csebuetnlp/BanglaNMT\"\n",
        "\n",
        "dataset = load_dataset(dataset_name)\n",
        "\n",
        "keys = list(dataset[\"train\"][0].keys())\n",
        "\n",
        "print(keys)"
      ],
      "metadata": {
        "id": "Vu4P0nHjYeaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus():\n",
        "    dataset = raw_datasets[\"train\"]\n",
        "    for start_idx in range(0, len(dataset), 1000):\n",
        "        samples = dataset[start_idx : start_idx + 1000]\n",
        "        yield samples[\"bn\"]"
      ],
      "metadata": {
        "id": "v2KAf3vxZrqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "training_corpus = get_training_corpus()\n",
        "new_tokenizer = old_tokenizer.train_new_from_iterator(training_corpus,52000)\n",
        "new_tokenizer.save_pretrained(\"\")#save the new tokanizer with a new name in your local directory and load the newly trained tokanizer for training the model"
      ],
      "metadata": {
        "id": "eY3nWePxZwvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"গল্পটিতে\"\n",
        "\n",
        "print(old_tokenizer.tokenize(example))\n",
        "print(new_tokenizer.tokenize(example))"
      ],
      "metadata": {
        "id": "VGcwSqNrZxkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BwLSAWmhNT2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define your model (example)\n",
        "class YourModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(YourModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(100, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = YourModel()\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 80\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    ...\n"
      ],
      "metadata": {
        "id": "xnQpM0Zimhzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to read different file types\n",
        "def read_pdf(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def read_word(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\"\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_txt(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def read_documents_from_directory(directory):\n",
        "    combined_text = \"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            combined_text += read_pdf(file_path)\n",
        "        elif filename.endswith(\".docx\"):\n",
        "            combined_text += read_word(file_path)\n",
        "        elif filename.endswith(\".txt\"):\n",
        "            combined_text += read_txt(file_path)\n",
        "    return combined_text\n"
      ],
      "metadata": {
        "id": "Ly_QfYPDHlie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_directory = '/content/my'\n",
        "text_data = read_documents_from_directory(train_directory)\n",
        "text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n"
      ],
      "metadata": {
        "id": "oobynnecHx87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/my/train.txt\", \"w\") as f:\n",
        "    f.write(text_data)"
      ],
      "metadata": {
        "id": "8RCPr_L0uJdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb #install wandb"
      ],
      "metadata": {
        "id": "TOJ6ApHY-keJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BengaliTokenizer\n",
        "# AutoTokenizer\n",
        "\n",
        "from transformers import AutoTokenizer, GPT2DoubleHeadsModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(train_file_path, val_file_path, tokenizer, block_size=128):\n",
        "    train_dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=train_file_path,\n",
        "        block_size=block_size,\n",
        "    )\n",
        "    val_dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=val_file_path,\n",
        "        block_size=block_size,\n",
        "    )\n",
        "    return train_dataset, val_dataset\n",
        "def load_data_collator(tokenizer, mlm=False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=mlm,\n",
        "    )\n",
        "    return data_collator  # Return the same data collator for both train and validation\n",
        "\n",
        "import csv\n",
        "import torch\n",
        "\n",
        "def compute_accuracy(labels_ids, preds_ids):\n",
        "    accuracy = (preds_ids == labels_ids).mean()\n",
        "    return accuracy.item()\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    labels_ids = p.label_ids\n",
        "    preds_ids = p.predictions.argmax(-1)\n",
        "    accuracy = compute_accuracy(labels_ids, preds_ids)\n",
        "\n",
        "    # Save the labels, predictions, and accuracy to a CSV file\n",
        "    with open(\"accuracy.csv\", \"w\", newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile, delimiter=\",\")\n",
        "        writer.writerow([\"Labels\", \"Predictions\", \"Accuracy\"])\n",
        "        for label, prediction in zip(labels_ids, preds_ids):\n",
        "            writer.writerow([label.tolist(), prediction.tolist(), accuracy])\n",
        "\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "\n",
        "def train(train_file_path, val_file_path, model_name,\n",
        "          output_dir,\n",
        "          overwrite_output_dir,\n",
        "          per_device_train_batch_size,\n",
        "          num_train_epochs,\n",
        "          save_steps, learning_rate):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Koustav_Tokenizer\")\n",
        "    train_dataset, val_dataset = load_dataset(train_file_path, val_file_path, tokenizer)\n",
        "    data_collator = load_data_collator(tokenizer)  # Use the same data collator for both training and validation\n",
        "\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    model = GPT2DoubleHeadsModel.from_pretrained(model_name)\n",
        "\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=overwrite_output_dir,\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        evaluation_strategy=\"steps\",  # Evaluate at specified steps\n",
        "        eval_steps=save_steps,\n",
        "        logging_steps=20, # Evaluate every `save_steps` during training\n",
        "    )\n",
        "\n",
        "    import csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,  # Set the validation dataset\n",
        "        compute_metrics=compute_metrics,\n",
        "       # Set the custom compute_metrics function\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_file_path = \"/content/my/train.txt\"\n",
        "val_file_path = \"/content/my/val.txt\"\n",
        "model_name = 'gpt2-medium'\n",
        "output_dir = '/content/my'\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 16\n",
        "num_train_epochs = 100\n",
        "save_steps = 20\n",
        "\n",
        "# Add a parameter to adjust the learning rate\n",
        "learning_rate = float(input(\"Enter the learning rate: \"))\n",
        "\n",
        "train(\n",
        "    train_file_path=train_file_path,\n",
        "    val_file_path=val_file_path,\n",
        "    model_name=model_name,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=overwrite_output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps,\n",
        "    learning_rate=learning_rate,\n",
        ")\n"
      ],
      "metadata": {
        "id": "rkStEuxUidyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "xwGS1IMlGBMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from transformers import EvalPrediction\n",
        "import csv\n",
        "\n"
      ],
      "metadata": {
        "id": "lelq_sN4Gy5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model = GPT2DoubleHeadsModel.from_pretrained(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Koustav_Tokenizer\")\n",
        "    return tokenizer\n",
        "\n",
        "def generate_text(model_path, prompt, max_new_tokens=50):\n",
        "    model = load_model(model_path)\n",
        "    tokenizer = load_tokenizer(model_path)\n",
        "    ids = tokenizer.encode(f'{prompt}', return_tensors='pt')\n",
        "    # Set max_length to a very large value to allow unrestricted text generation\n",
        "    final_outputs = model.generate(\n",
        "        ids,\n",
        "        do_sample=True,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        pad_token_id=model.config.eos_token_id,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.5,\n",
        "        early_stopping=True,  # Prevent the model from generating more text after the first end-of-sequence token\n",
        "         num_return_sequences=1,\n",
        "    )\n",
        "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "wOvrNQRAG2IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model got trained on the entire text and took much longer to train, and yet it fails to give meaningful results."
      ],
      "metadata": {
        "id": "BvNx7gjeRieD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1_path = \"/content/my\" #load your saved model\n",
        "\n",
        "prompt= \"হ্যালো, আপনি কেমন আছেন:\"\n",
        "max_new_tokens=100\n",
        "\n",
        "generate_text(model1_path,prompt, max_new_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mTDTrpnG5Ut",
        "outputId": "a12c5f68-a752-47a7-8d68-a09a046faee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "হ্যালো, আপনি কেমন আছেন: ফোনিয়ার প্রাধ্যক্ষ ড. জিয়া রহমান বিষয়টি নিশ্চিত করেন।\"\t\n",
            "\"Shafiqul Islam, Chief of Criminal Investigation Departmen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZHIECRog5kBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2DoubleHeadsModel, AutoTokenizer\n",
        "import csv\n",
        "\n",
        "def calculate_accuracy(logits, targets):\n",
        "    predicted_tokens = logits.argmax(dim=-1)\n",
        "    accuracy = (predicted_tokens == targets).float().mean()\n",
        "    return accuracy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your trained GPT-2 model and tokenizer (change the paths accordingly)\n",
        "    model_path = \"/content/my\"\n",
        "    tokenizer_path = \"\"#enter the path of the newly trained tokenizer\n",
        "    model = GPT2DoubleHeadsModel.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Initialize a list to store user inputs and their respective accuracies\n",
        "    user_inputs = []\n",
        "    accuracies = []\n",
        "\n",
        "    # Take at least 50 user inputs\n",
        "    while len(user_inputs) < 2:\n",
        "        user_input = input(\"Enter your text: \")\n",
        "        if user_input.strip():\n",
        "            user_inputs.append(user_input)\n",
        "\n",
        "            # Tokenize the user input and return PyTorch tensors\n",
        "            test_inputs = tokenizer([user_input], return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                input_ids = test_inputs[\"input_ids\"].unsqueeze(0)\n",
        "                outputs = model(input_ids)[0]\n",
        "\n",
        "                predicted_probs = F.softmax(outputs, dim=-1)\n",
        "\n",
        "                predicted_tokens = predicted_probs.argmax(dim=-1).squeeze()\n",
        "\n",
        "                target_tokens = input_ids.squeeze()\n",
        "\n",
        "                accuracy = calculate_accuracy(predicted_tokens, target_tokens)\n",
        "\n",
        "                accuracies.append(accuracy.item())\n",
        "\n",
        "    # Save the user inputs and accuracies to a CSV file\n",
        "    with open(\"user_accuracies.csv\", \"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"User Input\", \"Accuracy\"])\n",
        "        for user_input, accuracy in zip(user_inputs, accuracies):\n",
        "            writer.writerow([user_input, accuracy])\n",
        "\n",
        "    print(\"User inputs and accuracies have been saved to 'user_accuracies.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHWNgdocHFbZ",
        "outputId": "da52a14d-3e96-41d9-942b-4b0db34460f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: পোরকুপাইনরা কী খায়\t\n",
            "Enter your text: exit\n",
            "User inputs and accuracies have been saved to 'user_accuracies.csv'.\n"
          ]
        }
      ]
    }
  ]
}